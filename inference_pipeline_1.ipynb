{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "from inference import predict\n",
    "from transformations import normalize_01, re_normalize\n",
    "from unet import UNet\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "# root directory\n",
    "root = pathlib.Path.cwd() / \"Data\" / \"2018\"\n",
    "root_temp = pathlib.Path.cwd() / \"temp_chkp\"\n",
    "\n",
    "# load and process images from original images or load from saved pickle files\n",
    "USE_SAVED_IMG = True\n",
    "\n",
    "\n",
    "def get_filenames_of_path(path: pathlib.Path, ext: str = \"*\"):\n",
    "    \"\"\"Returns a list of files in a directory/path. Uses pathlib.\"\"\"\n",
    "    filenames = [file for file in path.glob(ext) if file.is_file()]\n",
    "    return filenames\n",
    "\n",
    "\n",
    "# input and target files\n",
    "images_names = get_filenames_of_path(root / \"ISIC2018_Task1-2_Validation_Input\", ext='*.jpg')\n",
    "targets_names = get_filenames_of_path(root / \"ISIC2018_Task1_Validation_GroundTruth\", ext='*.png')\n",
    "\n",
    "# load data from saved files\n",
    "if USE_SAVED_IMG:\n",
    "    with open(root_temp / \"test_images.pkl\", \"rb\") as f:\n",
    "        images_res = pickle.load(f)\n",
    "    with open(root_temp / \"test_targets.pkl\", \"rb\") as f:\n",
    "        targets_res = pickle.load(f)    \n",
    "\n",
    "else:\n",
    "    # read images and store them in memory\n",
    "    images = [imread(img_name) for img_name in images_names]\n",
    "    targets = [imread(tar_name) for tar_name in targets_names]\n",
    "\n",
    "    # Resize images and targets\n",
    "    images_res = [resize(img, (128, 128, 3)) for img in images]\n",
    "    resize_kwargs = {\"order\": 0, \"anti_aliasing\": False, \"preserve_range\": True}\n",
    "    targets_res = [resize(tar, (128, 128), **resize_kwargs) for tar in targets]\n",
    "\n",
    "    # change target label to show differetn color from prediction result\n",
    "    targets_res = [np.where(target==255, 1, target).astype(int) for target in targets_res]\n",
    "\n",
    "    # save images and targets\n",
    "    with open(root_temp / \"test_images.pkl\", \"wb\") as f:\n",
    "        pickle.dump(images_res, f)\n",
    "    with open(root_temp / \"test_targets.pkl\", \"wb\") as f:\n",
    "        pickle.dump(targets_res, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    torch.device(\"cpu\")\n",
    "\n",
    "# model\n",
    "model = UNet(\n",
    "    in_channels=3,\n",
    "    out_channels=2,\n",
    "    n_blocks=4,\n",
    "    start_filters=32,\n",
    "    activation=\"relu\",\n",
    "    normalization=\"batch\",\n",
    "    conv_mode=\"same\",\n",
    "    dim=2,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "model_name = \"test.pt\"\n",
    "model_weights = torch.load(pathlib.Path.cwd() / \"Output\" / model_name)\n",
    "\n",
    "model.load_state_dict(model_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# preprocess function\n",
    "def preprocess(img: np.ndarray):\n",
    "    img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]\n",
    "    img = normalize_01(img)  # linear scaling to range [0-1]\n",
    "    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]\n",
    "    img = img.astype(np.float32)  # typecasting to float32\n",
    "    return img\n",
    "\n",
    "\n",
    "# postprocess function\n",
    "def postprocess(img: torch.tensor):\n",
    "    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel\n",
    "    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray\n",
    "    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]\n",
    "    img = re_normalize(img)  # scale it to the range [0-255]\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\xyz\\dropbox\\selfprojects\\py38_pytorch_gpu\\venv\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "# predict the segmentation maps\n",
    "output = [predict(img, model, preprocess, postprocess, device) for img in images_res]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\xyz\\dropbox\\selfprojects\\py38_pytorch_gpu\\venv\\lib\\site-packages\\napari\\_vispy\\vispy_camera.py:109: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  zoom = np.min(canvas_size / scale)\n"
     ]
    }
   ],
   "source": [
    "from visual import enable_gui_qt\n",
    "\n",
    "enable_gui_qt()\n",
    "import napari\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "idx = 32\n",
    "img_nap = viewer.add_image(images_res[idx], name=\"Input\")\n",
    "tar_nap = viewer.add_labels(targets_res[idx], name=\"Target\")\n",
    "out_nap = viewer.add_labels(output[idx], name=\"Prediction\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}